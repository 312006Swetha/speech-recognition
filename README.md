# ğŸŒ AI Real-Time Speech Translator

An **AI Real-Time Speech Translator** is an intelligent system that listens to spoken language, automatically converts speech into text, translates it into multiple target languages, and generates spoken output in real time. It leverages advanced **speech recognition**, **natural language processing**, and **text-to-speech** technologies to enable seamless multilingual communication across digital platforms such as **OTT media**, **live broadcasts**, and **streaming applications**.

---

## ğŸ§© Problem Statement

The rapid expansion of **OTT platforms** and **live digital streaming** has increased the demand for multilingual content. However, live commentary and spoken media are often available in only one or two languages, limiting accessibility for diverse audiences.

Existing translation solutions lack:
- âš ï¸ Real-time performance  
- âš ï¸ Seamless integration with OTT feeds  
- âš ï¸ High-quality speech output  

Therefore, there is a need to develop an **AI-based real-time speech-to-speech translation system** that can accurately translate live **English and Hindi** commentary into **more than 12 languages**, integrate smoothly into **OTT digital feeds**, and enhance accessibility and user experience for a **global, multilingual audience**.

---

## ğŸ’¡ Proposed Solution

The proposed system is an **AI-based multilingual speech translation platform** that accepts:
- ğŸ§ Audio files  
- ğŸ¥ Video files  
- â–¶ï¸ YouTube links  

### Workflow:
1. Extracts audio from the input source  
2. Converts speech into text using a **deep learning ASR model**  
3. Translates the text into a **user-selected target language**  
4. Generates **natural-sounding speech output**  

To efficiently handle long audio streams, the system **splits audio into smaller chunks** before processing.

âœ… Improves accessibility  
âœ… Supports multiple **Indian and global languages**  
âœ… Provides both **text and audio outputs**  

---

## ğŸ› ï¸ Technology Stack

### ğŸ”¹ Backend
- **Flask** â€“ REST API development  
- **Python** â€“ Core programming language  

### ğŸ”¹ AI & Machine Learning
- **OpenAI Whisper** â€“ Speech-to-text (ASR)  
- **PyTorch** â€“ Deep learning framework  

### ğŸ”¹ Audio & Video Processing
- **Librosa** â€“ Audio loading and chunking  
- **FFmpeg** â€“ Audio extraction & format conversion  
- **yt-dlp** â€“ YouTube audio download  

### ğŸ”¹ Translation & Speech
- **GoogleTrans** â€“ Text translation  
- **gTTS (Google Text-to-Speech)** â€“ Speech synthesis  

### ğŸ”¹ Deployment Support
- **CUDA (Optional)** â€“ GPU acceleration  

---

## âš™ï¸ Installation and Setup

### Step 1: Clone the Repository
```bash
git clone <repository-url>
cd multilingual-speech-translation
```
### Step 2: Create Virtual Environment (Recommended)
```bash
python -m venv venv
source venv/bin/activate   # Linux / Mac
venv\Scripts\activate      # Windows

```
### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```
### ğŸ”¹ Step 4: Install FFmpeg
```bash
ffmpeg -version
```
### ğŸ”¹ Step 5: Download Whisper Model
```bash
./whisper
```

### ğŸ”¹ Step 6: Run the Application
```
python app.py
